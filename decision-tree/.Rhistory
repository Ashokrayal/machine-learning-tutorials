quit()
setwd("~/Codes/machine-learning-tutorials/decision-tree")
dataset = read.csv('dataset/car-evaluation/car.csv')
# Install all packages used in this tutorial
install.packages('C50')
View(dataset)
View(dataset)
View(dataset)
View(dataset)
criteria = dataset[1:7]
View(criteria)
View(criteria)
criteria = dataset[1:6]
View(criteria)
View(criteria)
# Encoding the target feature as factor
dataset$car = factor(dataset$car, levels = c(0, 1, 2, 3))
View(dataset)
View(dataset)
View(criteria)
dataset = read.csv('dataset/car-evaluation/car.csv')
c
dataset = read.csv('dataset/car-evaluation/car.csv')
criteria = dataset[1:6]
View(dataset)
View(dataset)
# Encoding the target feature as factor
dataset$car = factor(dataset$car, levels = c('unacc', 'acc', 'good', 'v-good'))
View(dataset)
View(dataset)
library(caTools)
split = sample.split(dataset$car, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Install all packages used in this tutorial
install.packages('C50')
# Install all packages used in this tutorial
install.packages('C50')
install.packages("~/Downloads/C50_0.1.1.tar.gz", repos = NULL, type = "source")
# Install all packages used in this tutorial
install.packages('C50')
# Aplly C50 algorithm
library(c50)
# Aplly C50 algorithm
library(C50)
View(criteria)
View(criteria)
remove(criteria)
tree = C5.0(formula = car ~ ., data = dataset)
remove(tree)
decTree = C5.0(formula = car ~ ., data = dataset)
decTree = C5.0(formula = car ~ ., data = training_set)
View(test_set)
View(test_set)
test_set[-7]
# Making prediction using model created by C50 algorithm
y_pred = predict(decTree, newdata = test_set[-7], type = 'class')
# Making the Confusion Matrix
cm = table(test_set[, 7], y_pred)
cm
# Plot the tree
plot(decTree)
# View model's summary
summary(decTree)
clear
dataset = read.csv('dataset/car-evaluation/car.csv')
View(dataset)
View(dataset)
dataset$car = factor(dataset$car, levels = c('unacc', 'acc', 'good', 'vgood'))
View(dataset)
View(dataset)
library(caTools)
split = sample.split(dataset$car, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
library(C50)
decTree = C5.0(formula = car ~ ., data = training_set)
y_pred = predict(decTree, newdata = test_set[-7], type = 'class')
cm = table(test_set[, 7], y_pred)
cm
plot(decTree)
# View model's summary
summary(decTree)
decTree
install.packages('gmodels')
s)
CrossTable(test_set$car,
y_pred,
prop.chisq = FALSE,
prop.c     = FALSE,
prop.r     = FALSE,
dnn = c('actual default', 'predicted default'))
CrossTable(test_set$car,
y_pred,
prop.chisq = FALSE,
prop.c     = FALSE,
prop.r     = FALSE,
dnn = c('actual default', 'predicted default'))
gmodels::CrossTable(test_set$car,
y_pred,
prop.chisq = FALSE,
prop.c     = FALSE,
prop.r     = FALSE,
dnn = c('actual default', 'predicted default'))
View(dataset)
View(dataset)
set,
aes(x=buying)) +
geom_histogram() +
scale_x_log10() +
ggtitle("Histogram buying") +
facet_wrap(~car)
# Analyzing data
library(ggplot2)
ggplot(data=dataset,
aes(x=buying)) +
geom_histogram() +
scale_x_log10() +
ggtitle("Histogram buying") +
facet_wrap(~car)
# Importing the dataset
dataset = read.csv('dataset/car-evaluation/car.csv')
y(ggplot2)
ggplot(data=dataset,
aes(x=buying)) +
geom_histogram() +
scale_x_log10() +
ggtitle("Histogram buying") +
facet_wrap(~ca
library(ggplot2)
ggplot(data=dataset,
aes(x=buying)) +
geom_histogram() +
scale_x_log10() +
ggtitle("Histogram buying") +
facet_wrap(~car)
library(ggplot2)
ggplot(data=dataset,
aes(x=buying)) +
geom_bar() +
ggtitle("Histogram buying") +
facet_wrap(~car)
set,
aes(x=main)) +
geom_bar() +
ggtitle("Histogram maintenance") +
facet_wrap(~car)
ot(data=dataset,
aes(x=maint)) +
geom_bar() +
ggtitle("Histogram maintenance") +
facet_wrap(~car)
ggplot(data=dataset,
aes(x=maint)) +
geom_bar() +
ggtitle("Histogram maintenance") +
facet_wrap(~car)
# Plot doors histogram
ggplot(data=dataset,
aes(x=doors)) +
geom_bar() +
ggtitle("Doors maintenance") +
facet_wrap(~car)
ggplot(data=dataset,
aes(x=doors)) +
geom_bar() +
ggtitle("Histogram doors") +
facet_wrap(~car)
ggplot(data=dataset,
aes(x=persons)) +
geom_bar() +
ggtitle("Histogram persons") +
facet_wrap(~car)
ggplot(data=dataset,
aes(x=lug_boots)) +
geom_bar() +
ggtitle("Histogram lugage boots") +
facet_wrap(~car)
ggplot(data=dataset,
aes(x=safety)) +
geom_bar() +
ggtitle("Histogram safety") +
facet_wrap(~car)
install.packages('mlr')
# Produce learning curves
library(mlr)
CurveData(
learners = c("classif.C50"),
task = sonar.task,
percs = seq(0.1, 1, by = 0.2),
measures = list(tp, fp, tn, fn),
resampling = makeResampleDesc(method = "CV", iters = 5),
show.info = FALSE)
plotLearningCurve(learningCurve)
learningCurve = generateLearningCurveData(
learners = c("classif.C50"),
task = sonar.task,
percs = seq(0.1, 1, by = 0.2),
measures = list(tp, fp, tn, fn),
resampling = makeResampleDesc(method = "CV", iters = 5),
show.info = FALSE)
plotLearningCurve(learningCurve)
dataset$car = factor(dataset$car, levels = c('unacc', 'acc', 'good', 'vgood'))
# Split label set into training set and test set with ratio 7:3
library(caTools)
split = sample.split(dataset$car, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
decTree = C5.0(formula = car ~ ., data = training_set)
# Making prediction using model created by C50 algorithm
y_pred = predict(decTree, newdata = test_set[-7], type = 'class')
learningCurve = generateLearningCurveData(
learners = c("classif.C50"),
task = list(test_set, training_set),
percs = seq(0.1, 1, by = 0.2),
measures = list(tp, fp, tn, fn),
resampling = makeResampleDesc(method = "CV", iters = 5),
show.info = FALSE)
plotLearningCurve(learningCurve)
learningCurve = generateLearningCurveData(
learners = decTree,
task = sonar.task,
percs = seq(0.1, 1, by = 0.2),
measures = list(tp, fp, tn, fn),
resampling = makeResampleDesc(method = "CV", iters = 5),
show.info = TRUE)
plotLearningCurve(learningCurve)
install.packages('caret')
library(mlr)
learningCurve = generateLearningCurveData(
learners = c("classif.C50"),
task = dataset,
percs = seq(0.1, 1, by = 0.2),
measures = list(tp, fp, tn, fn),
resampling = makeResampleDesc(method = "CV", iters = 5),
show.info = FALSE)
plotLearningCurve(learningCurve)
dataset.task
type(dataset)
makeClassifTask(id = "car", data = dataset, target = "Class")
makeClassifTask(id = "car", data = dataset, target = "car")
dataset.task = makeClassifTask(id = "car", data = dataset, target = "car")
learningCurve = generateLearningCurveData(
learners = c("classif.C50"),
task = dataset.task,
percs = seq(0.1, 1, by = 0.2),
measures = list(tp, fp, tn, fn),
resampling = makeResampleDesc(method = "CV", iters = 5),
show.info = FALSE)
plotLearningCurve(learningCurve)
learningCurve = generateLearningCurveData(
learners = c("classif.C50"),
task = dataset.task,
percs = seq(0.1, 1, by = 0.2),
resampling = makeResampleDesc(method = "CV", iters = 5),
show.info = FALSE)
plotLearningCurve(learningCurve)
library(mlr)
dataset.task = makeClassifTask(id = "car", data = dataset, target = "car")
learningCurve = generateLearningCurveData(
learners = c("classif.C50"),
task = dataset.task,
percs = seq(0.1, 1, by = 0.1),
resampling = makeResampleDesc(method = "CV", iters = 5, predict = 'both'),
measures = list(setAggregation(acc, train.mean), setAggregation(acc, test.mean)),
show.info = TRUE)
plotLearningCurve(learningCurve)
library(mlr)
dataset.task = makeClassifTask(id = "car", data = dataset, target = "car")
learningCurve = generateLearningCurveData(
learners = c("classif.C50"),
task = dataset.task,
percs = seq(0.1, 1, by = 0.1),
resampling = makeResampleDesc(method = "CV", iters = 5, predict = 'both'),
measures = list(setAggregation(acc, train.mean), setAggregation(acc, test.mean)),
show.info = TRUE)
plotLearningCurve(learningCurve)
learningCurve = generateLearningCurveData(
learners = c("classif.C50"),
task = dataset.task,
percs = seq(0.1, 1, by = 0.1),
resampling = makeResampleDesc(method = "CV", iters = 5),
measures = list(setAggregation(acc, train.mean), setAggregation(acc, test.mean)),
show.info = TRUE)
plotLearningCurve(learningCurve, facet = measures)
learningCurve = generateLearningCurveData(
learners = c("classif.C50"),
task = dataset.task,
percs = seq(0.1, 1, by = 0.1),
resampling = makeResampleDesc(method = "CV", iters = 5, predict = 'both'),
measures = list(setAggregation(acc, train.mean), setAggregation(acc, test.mean)),
show.info = TRUE)
plotLearningCurve(learningCurve, facet = measures)
plotLearningCurve(learningCurve, facet = measureACC)
plotLearningCurve(learningCurve, facet = 'measure')
plotLearningCurve(learningCurve, facet = 'learner')
# View model's summary
summary(decTree)
dataset = read.csv('dataset/car-evaluation/car.csv')
dataset$car = factor(dataset$car, levels = c('unacc', 'acc', 'good', 'vgood'))
library(caTools)
split = sample.split(dataset$car, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
library(C50)
decTree = C5.0(formula = car ~ ., data = training_set)
y_pred = predict(decTree, newdata = test_set[-7], type = 'class')
summary(decTree)
[1 2]
test_set[1]
test_set[1, 1]
test_set[1, :]
test_set[1, 1:end]
test_set[1,]
typeof(test_set[1,])
# Predict choosen decision using model
decision = list(vhigh, vhigh, 2, 2, small, med, unacc)
# Predict choosen decision using model
decision = list('vhigh', 'vhigh', 2, 2, 'small', 'med')
pred_dec = predict(decTree, decision, type = 'class')
pred_dec = predict(decTree, newdata = decision, type = 'class')
View(test_set)
View(test_set)
pred_dec = predict(decision, decTree, type = 'class')
pred_dec = predict(decTree, newdata = decision, type = 'class')
View(test_set)
View(test_set)
# Predict choosen decision using model
decision = list(buying='vhigh', 'vhigh', 2, 2, 'small', 'med')
# Predict choosen decision using model
decision = list(buying='vhigh', maint='vhigh', doors=2, persons=2, lug_boots='small', safety='med')
pred_dec = predict(decTree, newdata = decision, type = 'class')
pred_dec
decision$buying
typeof(dataset)
typeof(dataset)
typeof(dataset[1,])
dataset[1,]
# Predict choosen decision using model
decision = list(buying='vhigh', maint='vhigh', doors=2, persons=2, lug_boots='small',
safety='med')
# Since doors and persons are categorial, then we need transform it into factor
decision$doors = factor(decision$doors, levels = c(2, 3, 4, '5more'))
decision$persons = factor(decision$persons, levels = c(2, 4, 'more'))
pred_dec = predict(decTree, newdata = decision, type = 'class')
pred_dec
decision = list(persons=4, buying='medium', maint='low',
lug_boots='medium', safety='med', doors=4)
decision$doors = factor(decision$doors, levels = c(2, 3, 4, '5more'))
decision$persons = factor(decision$persons, levels = c(2, 4, 'more'))
pred_dec = predict(decTree, newdata = decision, type = 'class')
list(persons=4, buying='medium', maint='low',
lug_boots='med', safety='med', doors=4)
# Since doors and persons are categorial, then we need transform it into factor
decision$doors = factor(decision$doors, levels = c(2, 3, 4, '5more'))
decision$persons = factor(decision$persons, levels = c(2, 4, 'more'))
pred_dec = predict(decTree, newdata = decision, type = 'class')
list(persons=4, buying='med', maint='low',
lug_boots='med', safety='med', doors=4)
# Since doors and persons are categorial, then we need transform it into factor
decision$doors = factor(decision$doors, levels = c(2, 3, 4, '5more'))
decision$persons = factor(decision$persons, levels = c(2, 4, 'more'))
pred_dec = predict(decTree, newdata = decision, type = 'class')
decision = list(persons=4, buying='med', maint='low',
lug_boots='med', safety='med', doors=4)
# Since doors and persons are categorial, then we need transform it into factor
decision$doors = factor(decision$doors, levels = c(2, 3, 4, '5more'))
decision$persons = factor(decision$persons, levels = c(2, 4, 'more'))
pred_dec = predict(decTree, newdata = decision, type = 'class')
pred_dec
decTree
cm
# Importing the dataset
dataset = read.csv('dataset/car-evaluation/car.csv')
# Encode label as factor
dataset$car = factor(dataset$car, levels = c('unacc', 'acc', 'good', 'vgood'))
library(caTools)
split = sample.split(dataset$car, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
library(C50)
decTree = C5.0(formula = car ~ ., data = training_set)
y_pred = predict(decTree, newdata = test_set[-7], type = 'class')
cm = table(test_set[, 7], y_pred)
cm
library(gmodels)
gmodels::CrossTable(test_set$car,
y_pred,
prop.chisq = FALSE,
prop.c     = FALSE,
prop.r     = FALSE,
dnn = c('actual default', 'predicted default'))
install.packages('ROCR')
install.packages('caret')
# Evaluate model prediction error
# View model's summary
summary(decTree)
library(ROCR)
rp = performance(pred, "prec", "rec")
plot(rp)
rorc = performance(pred, "tpr", "fpr");
plot(rorc);
library(ROCR)
rp = performance(y_pred, "prec", "rec")
plot(rp)
rorc = performance(y_pred, "tpr", "fpr");
plot(rorc);
library(ROCR)
pred = prediction(y_pred, test_set[-7])
rp = performance(pred, "prec", "rec")
plot(rp)
rorc = performance(pred, "tpr", "fpr");
plot(rorc);
library(ROCR)
pred = prediction(y_pred, test_set[7])
rp = performance(pred, "prec", "rec")
plot(rp)
rorc = performance(pred, "tpr", "fpr");
plot(rorc);
pred = prediction(as.numeric(y_pred), as.numeric(test_set[7]))
class(y_pred)
pred = prediction(as.numeric(unlist(y_pred)), as.numeric(unlist(test_set[7])))
as.numeric(unlist(y_pred))
# Computer Precission, Recall, and F1 Score
precission = diag(cm) / colSums(cm)
recall = diag(cm) / rowSums(cm)
f1_score = ifelse(precision + recall == 0, 0, 2 * precision * recall / (precision + recall))
f1_score = ifelse(precision + recall == 0, 0, 2 * precision * recall / (precision + recall))
# Computer Precission, Recall, and F1 Score
precision = diag(cm) / colSums(cm)
remove(precission)
precision
recall
f1_score
f1_score = ifelse(precision + recall == 0, 0, 2 * precision * recall / (precision + recall))
f1_score
# Evaluate model prediction error
# View model's summary
summary(decTree)
install.packages('PRROC')
# Evaluate model prediction error using precision-recall curve and RORC curve
library(PRROC)
precission
precision
cm = as.matrix(table(test_set[, 7], y_pred))
cm
# Evaluate model prediction error
# View model's summary
summary(decTree)
# Evaluate model prediction error using precision-recall and F1 score
precision = diag(cm) / colSums(cm)
recall = diag(cm) / rowSums(cm)
f1_score = ifelse(precision + recall == 0, 0, 2 * precision * recall / (precision + recall))
precision
recall
f1_score
pred_dec
